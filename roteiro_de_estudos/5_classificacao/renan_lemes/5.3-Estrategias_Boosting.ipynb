{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Estratégias de Boosting.\r\n",
    "Os métodos de boosting é uma categoria de Ensemble Learning, com foco principalmente em diminuir o viés dos modelos. Tem com base treinar vários modelos simples com a finalidade de produzir um modelo final e mais robusto, no entanto nos algoritmos de Boonsting, os modelos  não são mais treinados de forma independente entre si, mas de maneira sequencial, a partir de um ajuste dos modelos treinados previamentes.\r\n",
    "$\\newline$ Para maximizar o desempenho preditor ele treina interativamente novos  modelos com um foco nas observações que os modelos anteriores erraram mais, tornando a predição mais resistente ao viés, assim atualiza o modelo para priorizar as novas predições.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boostings Gradient.\r\n",
    "Ao  invés de estabelecer pesos para o weak learners, o Gradient terina novos modelos diretamente no erro dos modelos anteriores, ou seja, os novos modelos tentam prever o erro dos modelos anteriores em vez de prever o erro dos modelos anteriores em vez de prever independente o target.\r\n",
    "$\\newline$ O primerio modelo faz uma aproximação bem simples para predição, e obtemos os nossos erros residuais (observando menos e previsto), depois, treinamos mais modelos nesses erros residuais para tentar predizer o erro do primeiro modelo. Assim forma, quando somamos as predições de cada modelo para obter a predição final, obtemos uma versão mais corrigida da primeira predição.\r\n",
    "\r\n",
    "![img](https://datarisk.io/wp-content/uploads/2020/06/Captura-de-tela-de-2020-06-06-21-52-32.png)\r\n",
    "\r\n",
    "Repetimos esse processo por várias iterações, obtendo erros residuais cada vez menores.\r\n",
    "\r\n",
    "![img](https://datarisk.io/wp-content/uploads/2020/06/Captura-de-tela-de-2020-06-06-21-53-27.png)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Boosting ADA.\r\n",
    "Adaptive Boosting é um algoritmo que consiste em combinar de forma sequêncial vários modelos mais fracos, sendo assim o weak learner subsequencial leva em consideração as predições do anterior, para formar um preditor mais conciso. O diferencial desse algoritmo é que as predições mais dificeis recebem um peso maior no preditor seguinte, assim buscando maior otimização do algoritmo final.\r\n",
    "\r\n",
    "![img](https://datarisk.io/wp-content/uploads/2020/06/Captura-de-tela-de-2020-06-06-21-51-44.png)\r\n",
    "\r\n",
    "Se reparamos aqui existe dois pesos. O primeiro é para cada observação que representa o grau de foco que a interação em questão deve dar para aquela observação. A cada novo modelo treinado, esse peso das amostras são atualizados, já o segundo é um peso para cada modeloque representa seu poder de decisão quando os modelos combinados. Eles são atribuidos apenas uma vez para cada estimador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pratica."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "\r\n",
    "from numpy import mean\r\n",
    "from numpy import std\r\n",
    "from sklearn.datasets import make_classification\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from sklearn.ensemble import GradientBoostingClassifier\r\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
    "from matplotlib import pyplot \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "def get_dataset():\r\n",
    "    X,y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\r\n",
    "    return (X,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def get_models():\r\n",
    "    models = dict()\r\n",
    "    n_trees = [10,50,100,500,1000,5000]\r\n",
    "    for n in n_trees:\r\n",
    "        models[str(n)] = GradientBoostingClassifier(n_estimators=n)\r\n",
    "    return models"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "def evaluate_model(model,X,y):\r\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10,n_repeats=3,random_state=1)\r\n",
    "    score = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\r\n",
    "    return score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "X, y = get_dataset()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "models = get_dataset()\r\n",
    "models"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[ 0.2929949 , -4.21223056, -1.288332  , ..., -4.43170633,\n",
       "         -2.82646737,  0.44916808],\n",
       "        [-0.06839901,  5.51884147, 11.2389773 , ..., -3.08994781,\n",
       "          1.19029898,  1.62025622],\n",
       "        [ 0.73161622, -0.68468633, -0.98174194, ...,  5.65429655,\n",
       "         -0.64659866, -3.15652999],\n",
       "        ...,\n",
       "        [ 0.81230832,  0.29333773,  3.55727154, ...,  7.52278375,\n",
       "         -4.50067701, -1.92525878],\n",
       "        [ 2.62760166, -1.9607565 , -7.1050466 , ...,  0.02433393,\n",
       "         -0.77573778,  4.04660465],\n",
       "        [-0.97292653,  0.76166769,  3.98307684, ...,  0.85864477,\n",
       "          2.406057  ,  2.33338943]]),\n",
       " array([1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "        1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 1, 1, 0, 0, 1]))"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "resuts, names = list(), list()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "for name,model in models.items():\r\n",
    "\tscores = evaluate_model(model, X, y)\r\n",
    "\tresults.append(scores)\r\n",
    "\tnames.append(name)\r\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'items'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-15b2d12fc17f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'>%s %.3f (%.3f)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'items'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "f763c5ae1380102371fc37b7f9e900cc55027b2a662d6fbcccf1534945890ce5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
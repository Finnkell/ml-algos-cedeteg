{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28e377c",
   "metadata": {},
   "source": [
    "# 3.2 - Validações holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076183e",
   "metadata": {},
   "source": [
    "## 3.2.1 - Introdução:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9624e",
   "metadata": {},
   "source": [
    "Antes de definir o método holdout, precisamos entender o que é validação cruzada:\n",
    "* **Validação Cruzada (Cross Validation):** É uma técnica que avalia a capacidade de generalização de um modelo. É muito usada quando fazemos a predição de valores. Consiste na partição dos dados em dados de treino e dados de teste, essa divisão é feita em uma porcentagem.\n",
    "<img src=\"https://miro.medium.com/max/1056/1*2fW8Y8gDEgUMIWO8z3-cLQ.png\" width=500px></img>\n",
    "\n",
    "\n",
    "* **Holdout:** É um tipo simples de validação cruzada. Este método consiste na divisão dos dados em duas partes, uma parte para **treino** e a outra parte para **teste**, onde antes dos dados serem testados, eles precisam passar pelo treinamento para que seja feito previsões do modelo treinado sobre o restante dos dados. Esse método faz uma divisão aleatória de 70% dos dados para treino e 30% para teste. A imagem abaixo ilustra esta divisão sobre o total de dados:\n",
    "\n",
    "<img src=\"https://static.wixstatic.com/media/ec9f84_2afbd552b2954e31913e725431d7f772~mv2.png/v1/fill/w_515,h_315,al_c/ec9f84_2afbd552b2954e31913e725431d7f772~mv2.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153334cf",
   "metadata": {},
   "source": [
    "O código abaixo exemplifica o uso do método holdout para a divisão dos dados em 70-30:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee19905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris.target\n",
    "\n",
    "# Método Holdout: 70-30\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)\n",
    "clf = svm.SVC(gamma='auto')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5, scoring='accuracy')\n",
    "print('Mean: ', scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb7001",
   "metadata": {},
   "source": [
    "## 3.2.2 - Leave One Out:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c581e",
   "metadata": {},
   "source": [
    "Este método é uma ramificação do K-Fold, onde temos o K igual a N, que define o número total de dados. Outra diferença do K-Fold, é que a estimativa de erro é calculada N vezes, uma para cada dado. Este processo é semelhante método estatístico Jack-Knife. A imagem abaixo ilustra cada uma das iterações de acordo com o total de dados (N):\n",
    "\n",
    "<img src=\"https://dataaspirant.com/wp-content/uploads/2020/12/7-LOOCV-Leave-One-Out-Cross-Validation.png\" width=500px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf9ade",
   "metadata": {},
   "source": [
    "O código abaixo exemplifica o uso de Leave One Out em um modelo de classificação Random Forest (a métrica usada para avaliar o modelo foi a acurácia):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16832a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.990\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X, y = make_blobs(n_samples=100, random_state=1)\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "y_true, y_pred = list(), list()\n",
    "for train_ix, test_ix in cv.split(X):\n",
    "    X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "\n",
    "    model = RandomForestClassifier(random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    yhat = model.predict(X_test)\n",
    "\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(yhat[0])\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f42a5",
   "metadata": {},
   "source": [
    "## 3.2.3 - K-Fold:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa736d",
   "metadata": {},
   "source": [
    "É uma técnica simples de validação cruzada. É conhecida como K-Fold, pois o K significa o número de subdivisões feitas, e o Fold significa cada um dos blocos de cada k, ou seja, esta técnica consiste em uma divisão dos dados em k subpartes, após isso o método holdout é repetido k vezes. A estimativa de erro é calculada de acordo com as k tentativas para obter a eficácia do modelo. A imagem abaixo representa o uso do K-Fold, onde k = 5:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/601/0*O_491U1UfF1lIqz_.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001647ae",
   "metadata": {},
   "source": [
    "O código abaixo exemplifica o uso de K-Fold em um modelo de Regressão Logística (a métrica usada para avaliar o modelo foi a acurácia):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecf0041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.868 (0.032)\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e1c8e",
   "metadata": {},
   "source": [
    "## 3.2.4 - Out of Sample:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9c569e",
   "metadata": {},
   "source": [
    "Existem os dados amostrais que usamos e os que ficam de fora da amostra. Esses dados que nós usamos são chamados de In-sample, pois os modelos são aplicados com base nesses dados. E os dados que ficaram de fora são chamados de Out-of-sample, pois eles são \"ignorados\" pelo modelo.\n",
    "\n",
    "Quando estamos tentando aplicar os modelos no mercado financeiro, podemos dizer que estamos buscando pelos dados que estão fora da amostra, pois o modelo vai prever por exemplo, os valores futuros de fechamento dos candles com base em dados históricos de um ativo.\n",
    "\n",
    "A imagem abaixo ilustra os dados In-sample e Out-of-sample:\n",
    "\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/6cviv.png\" width=500px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79cc145",
   "metadata": {},
   "source": [
    "## 3.2.5 - Out of Time:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6883ba98",
   "metadata": {},
   "source": [
    "A validação Out-of-time é definida como a tentativa de testar os dados em um período que está fora do previsto, ou seja, se o modelo foi treinado desde 2017-2019 com base em dados históricos, e se o modelo for testado, mas agora no ano de 2020, estamos fazendo uma validação Out-of-time. A vantagem de se usar essa abordagem é o que modelo está abilitado a identificar valores fora do intervalo que era previsto. Porém isso não é levado em consideração na hora de construir o modelo, pois selecionamos um modelo que tenha um bom desempenho nos dados de validação In-time. A imagem abaixo ilustra essa abordagem:\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Nathaniel-Bastian/publication/330870705/figure/fig4/AS:722795965194240@1549339395552/Spatial-Out-of-time-validation.ppm\" width=700px></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e17dc",
   "metadata": {},
   "source": [
    "## 3.2.6 - Conclusão:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081ab3f",
   "metadata": {},
   "source": [
    "Usamos os métodos de validação no mercado financeiro, através da análise de dados, pois quando importamos os dados, dividimos os dados para treino e para teste. Um método usado é o Out-of-sample, que abilita o modelo a ser usado em dados que ainda não foram vistos.\n",
    "\n",
    "<img src=\"https://aostrading.cz/wp-content/uploads/2015/08/In-Sample-and-Out-of-Sample-test.jpg\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

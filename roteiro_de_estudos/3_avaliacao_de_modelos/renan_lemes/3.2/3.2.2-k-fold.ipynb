{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# K-fold.\r\n",
    "O método de validação cruzada k-foid consiste em dividir o conjunto total de dados em $k$ conjuntos mutuamente exclusivos do mesmo tamanho e, a partir dai, um subconjunto é utilizado para o teste e os $k-1$ restantes são utilizados para estimação dos parâmetros, fazendo-se o cálculo da acurácia do modelo. Este processo é realizado $k$ vezes alterando de forma circular o subconjunto de teste.\r\n",
    "$\\newline$ Ao final das $k$ iterações calcula-se a acurácia sobre os erros encontrados, através da equação descrita anteriormente, obtendo assim uma medida mais confiável sobre a capacidade do modelo de representar o processo gerador dos dados."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![img](https://www.philschmid.de/fa30cbf6e298a32b0fcf90b6752503cb/k-fold.svg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definição.\r\n",
    "a amostra é $d$ é dividida em $K$ partes $(d_1, d_2, ..., d_{K})$ de tamanho parecido $m_k$ , em que :\r\n",
    "$$\\sum^{k}_{k=1} m_k = n$$\r\n",
    "$\\newline$ O Processo terá $K$ iterações onde, em cada iteração, a amostra de validação será dada por $d_k$, com $k=1,2,...,K$, e a amostra de treino para a criação do preditor será o conjunto das outras $K-1$ partes, ou seja, $d_{-k} = {d_1, d_2, ..., d_{k-1}, d_{k+1},...,d_{K}}$, assim no final dos passos, teríamos usado todos os dados tanto na parte de treino quanto na parte de validação.\r\n",
    "$$kfK = \\frac{1}{K} \\sum^{K}_{k=1} \\frac{1}{m_k} \\sum^{m_k}{i=1} L(y_{ik}, \\widehat{f}_{-k} (x_{ik})$$\r\n",
    "* $\\widehat{f}_{-k}(X)$ éo preditor \r\n",
    "* Amostra de treino $d_{-k}$\r\n",
    "* $d_k$ observações da amostra.\r\n",
    "* $k=1,2,...,K$ amostra parcionada."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prática."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.datasets import make_blobs\r\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "X, y = make_blobs(n_samples=10,random_state=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "X"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ -7.23731039,  -9.03108652],\n",
       "       [ -8.16550136,  -7.00850439],\n",
       "       [ -7.02266844,  -7.57041289],\n",
       "       [ -8.86394306,  -5.05323981],\n",
       "       [  0.08525186,   3.64528297],\n",
       "       [ -0.79415228,   2.10495117],\n",
       "       [ -1.34052081,   4.15711949],\n",
       "       [-10.32012971,  -4.3374029 ],\n",
       "       [ -2.18773166,   3.33352125],\n",
       "       [ -8.53560457,  -6.01348926]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f763c5ae1380102371fc37b7f9e900cc55027b2a662d6fbcccf1534945890ce5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
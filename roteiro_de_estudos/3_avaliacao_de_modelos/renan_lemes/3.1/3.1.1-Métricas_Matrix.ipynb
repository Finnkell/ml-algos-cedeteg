{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Méticas.\r\n",
                "* KS (Classificação)\r\n",
                "* Gini (Classificação)\r\n",
                "* AUC (Classificação)\r\n",
                "* RMSE (Regressão)\r\n",
                "* MAE (Regressão)\r\n",
                "* F1 (Classificação)\r\n",
                "* Recall (Classificação)\r\n",
                "* Precision (Classificação)\r\n",
                "* R2 (Regressão)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 3.1.1Métricas\r\n",
                "Durante o processo de criação de um modelo de machine learning nós precisamos medir a qualidade dele de acordo com o objetivo da tarefa. Existem funções matemáticas que nos ajudam a avaliar a capacidade de erro e acerto dos nossos modelos, e agora você conhecerá algumas das mais utilizadas. Na pesquisa, usarei a palavra métrica para me referir a essas funções.\r\n",
                "\r\n",
                "Tão importante quanto saber escolher um bom modelo, é saber escolher a métrica correta para decidir qual é o melhor entre eles.\r\n",
                "\r\n",
                "Existem métricas mais simples, outras mais complexas, algumas que funcionam melhor para datasets com determinadas características, ou outras personalizadas de acordo com o objetivo final do modelo.\r\n",
                "* Exemplos de métricas usadas:\r\n",
                "    * Registro de defeitos: quantidade de defeitos descobertos em relação aos resolvidos, por iteração;\r\n",
                "    * Cobertura de caso de teste: quantidade de casos de teste executados em relação à quantidade total de casos de teste;\r\n",
                "    * Cobertura de código: percentual do código que foi testando."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 3.1.2 Váriaveis.\r\n",
                "* TP - True positive - significa uma classificação correta da classe positiva, exemplo a classe real é possitivo e o modelo classificou como possitivo.\r\n",
                "* TN - True negative - significa uma classificação correta da classe negative, exemplo a classe real é negativo e o modelo classificou como negativo.\r\n",
                "* FP - False positive - significa uma classificação errada da classe possitivo, exemplo a classe real é negativo e o modelo classificou como positivo.\r\n",
                "* FN - False negative - significa uma classificação errada da classe negativo, por exemplo, a classe real é positivo e o modelo classificou como negativo.\r\n",
                "### Calculando.\r\n",
                "* TPR = $\\frac{TP}{Actual Positive} = \\frac{TP}{TP+FN}$\r\n",
                "\r\n",
                "* TNR = $\\frac{FN}{Actual Positive} = \\frac{FN}{TP+FN}$\r\n",
                "\r\n",
                "* FPR = $\\frac{TN}{Actual Negative} = \\frac{TN}{TN+FP}$\r\n",
                "\r\n",
                "* FNR = $\\frac{FP}{Actual Negative} = \\frac{FP}{TN+FP}$"
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# 3.1.3 Confusion Matrix.\r\n",
                "Em análise preditiva, a matriz de confusão conhecida também por matriz erro, é uma tabela de duas linhas e duas colunas que relata o número de falsos possitivos, falsos negativos, verdadeiros possitivos e verdadeiro negativos. Isso permite a análise mais detalhada de classificações corretas.\r\n",
                "$\\newline$ A precisão produzirá resultados enganosos se o conjunto de dados estiver desequilibrado, isto é, quando o número de observações em diferêntes classes variam muito.\r\n",
                "* Exemplo:\r\n",
                "Se houver $95$ gatos e apenas $5$ cachorros nos dados, um determinado classificador pode classificar todas as observações como gatos. A precisão geral seria de 95%, mas com mais detalhes o classificador teria uma taxa de reconhecimento de 100% para a classe de gatos, mas uma taxa de reconhecimento de 0% para a classe de cães."
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Pratica."
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "data = {'y_Actual':    [0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0],\r\n",
                "        'y_Predicted': [1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0]\r\n",
                "        }\r\n",
                "\r\n",
                "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\r\n",
                "\r\n",
                "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\r\n",
                "print (confusion_matrix)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Predicted  0  1\n",
                        "Actual         \n",
                        "0          4  2\n",
                        "1          2  4\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "source": [
                "from sklearn.metrics import confusion_matrix\r\n",
                "\r\n",
                "y_true = [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]\r\n",
                "y_pred =  [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\r\n",
                "confusion_m = confusion_matrix(y_true, y_pred)\r\n",
                "print(confusion_m)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "[[5 2]\n",
                        " [1 4]]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "source": [
                "print(\"\\nTP (True Positive) = {}\\nFP (False Positive) = {} \\nFN (False Negative) = {}\\nTN (True Negative) = {}\".format(confusion_m[0][0], confusion_m[0][1],confusion_m[1][0], confusion_m[1][1]))"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "TP (True Positive) = 5\n",
                        "FP (False Positive) = 2 \n",
                        "FN (False Negative) = 1\n",
                        "TN (True Negative) = 4\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "source": [
                "import pandas as pd\r\n",
                "\r\n",
                "data = {'y_Actual':    [1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0],\r\n",
                "        'y_Predicted': [1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\r\n",
                "        }\r\n",
                "\r\n",
                "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\r\n",
                "\r\n",
                "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\r\n",
                "print (confusion_matrix)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Predicted  0  1\n",
                        "Actual         \n",
                        "0          5  2\n",
                        "1          1  4\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.11",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.11 64-bit ('base': conda)"
        },
        "interpreter": {
            "hash": "f763c5ae1380102371fc37b7f9e900cc55027b2a662d6fbcccf1534945890ce5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}